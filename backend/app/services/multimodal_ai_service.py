import asyncio
import openai
import tempfile
import os
from typing import Dict, Any, List, Optional
from datetime import datetime
from .context_classifier_service import context_classifier

class MultimodalAIService:
    """Servi√ßo IA Multimodal REAL com OpenAI"""
    
    def __init__(self):
        self.openai_client = openai.OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    
    async def analyze_multimodal(self, patient_info: str, audio_bytes: bytes = None, image_bytes: bytes = None) -> Dict[str, Any]:
        """An√°lise multimodal REAL com Whisper + GPT-4"""
        try:
            print(f"üß† An√°lise multimodal REAL iniciada")
            
            # 1. TRANSCRI√á√ÉO REAL COM WHISPER
            transcription = ""
            if audio_bytes:
                transcription = await self._transcribe_audio_real(audio_bytes)
                print(f"üé§ Whisper transcreveu: {len(transcription)} caracteres")
            else:
                transcription = "Consulta baseada apenas em informa√ß√µes textuais fornecidas"
            
            # 2. AN√ÅLISE DE DOCUMENTOS (se fornecido)
            document_analysis = ""
            if image_bytes:
                document_analysis = f"Documento analisado: {len(image_bytes)} bytes processados"
                print(f"üìÑ Documento processado")
            
            # 3. CLASSIFICA√á√ÉO INTELIGENTE DE CONTEXTO
            context_analysis = context_classifier.classify_context(
                patient_info, transcription, document_analysis
            )
            
            context_type = context_analysis['main_context']
            print(f"üéØ Contexto identificado: {context_type}")
            
            # 4. OBTER PROMPTS ESPECIALIZADOS
            specialized_prompts = context_classifier.get_specialized_prompt(
                context_type, patient_info, transcription
            )
            
            # 5. GERAR ANAMNESE REAL COM GPT-4
            anamnese = await self._generate_real_anamnese(
                specialized_prompts['anamnese_prompt'],
                patient_info,
                transcription,
                context_type
            )
            
            # 6. GERAR LAUDO REAL COM GPT-4
            laudo = await self._generate_real_laudo(
                specialized_prompts['laudo_prompt'],
                anamnese,
                patient_info,
                transcription,
                context_type
            )
            
            return {
                "success": True,
                "transcription": transcription,
                "anamnese": anamnese,
                "laudo_medico": laudo,
                "document_analysis": document_analysis,
                "context_analysis": context_analysis,
                "specialized_type": context_type,
                "modalities_used": {
                    "text": bool(patient_info),
                    "audio": bool(audio_bytes),
                    "image": bool(image_bytes)
                },
                "model": "GPT-4o + Whisper + Context Intelligence",
                "confidence": context_analysis['confidence'],
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            print(f"‚ùå Erro na an√°lise multimodal: {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "fallback_mode": True
            }
    
    async def _transcribe_audio_real(self, audio_bytes: bytes) -> str:
        """Transcri√ß√£o REAL com Whisper-1"""
        try:
            # Salvar √°udio temporariamente
            with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as temp_audio:
                temp_audio.write(audio_bytes)
                temp_audio_path = temp_audio.name
            
            print(f"üé§ Enviando para Whisper: {len(audio_bytes)} bytes")
            
            # Transcrever com Whisper-1
            with open(temp_audio_path, "rb") as audio_file:
                transcript = self.openai_client.audio.transcriptions.create(
                    model="whisper-1",
                    file=audio_file,
                    language="pt"
                )
            
            # Limpar arquivo tempor√°rio
            os.unlink(temp_audio_path)
            
            transcription_text = transcript.text
            print(f"‚úÖ Whisper retornou: {transcription_text[:100]}...")
            
            return transcription_text
            
        except Exception as e:
            print(f"‚ö†Ô∏è Erro Whisper: {str(e)}")
            # Fallback para simula√ß√£o
            return f"[Erro Whisper] √Åudio de {len(audio_bytes)} bytes recebido mas n√£o processado: {str(e)}"
    
    async def _generate_real_anamnese(self, base_prompt: str, patient_info: str, transcription: str, context_type: str) -> str:
        """Gera anamnese REAL usando GPT-4"""
        
        enhanced_prompt = f"""
{base_prompt}

DADOS ESPEC√çFICOS PARA ANAMNESE:

**INFORMA√á√ïES DO PACIENTE:**
{patient_info}

**TRANSCRI√á√ÉO REAL DA CONSULTA:**
{transcription}

**CONTEXTO IDENTIFICADO:** {context_type.upper()}

INSTRU√á√ïES ESPEC√çFICAS:
- Use APENAS as informa√ß√µes fornecidas acima
- Mantenha linguagem m√©dica t√©cnica e precisa
- Estruture conforme o contexto {context_type}
- Extraia dados reais da transcri√ß√£o
- Se informa√ß√£o n√£o foi mencionada, indique como "N√£o relatado"
- Seja detalhado mas objetivo

Gere a anamnese estruturada REAL baseada nos dados fornecidos:
"""
        
        try:
            print(f"ü§ñ Gerando anamnese com GPT-4 para contexto: {context_type}")
            
            response = self.openai_client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {
                        "role": "system", 
                        "content": f"Voc√™ √© um m√©dico especialista gerando anamnese estruturada para {context_type}. Use apenas informa√ß√µes fornecidas."
                    },
                    {
                        "role": "user", 
                        "content": enhanced_prompt
                    }
                ],
                max_tokens=1500,
                temperature=0.2
            )
            
            anamnese_real = response.choices[0].message.content
            print(f"‚úÖ Anamnese gerada: {len(anamnese_real)} caracteres")
            
            return anamnese_real
            
        except Exception as e:
            print(f"‚ùå Erro GPT anamnese: {str(e)}")
            return f"""## ‚ùå ERRO NA GERA√á√ÉO DA ANAMNESE

**Erro:** {str(e)}

**Dados recebidos:**
- Paciente: {patient_info}
- Transcri√ß√£o: {transcription[:200]}...
- Contexto: {context_type}

*Configure corretamente a chave OpenAI para funcionalidade completa*"""
    
    async def _generate_real_laudo(self, base_prompt: str, anamnese: str, patient_info: str, transcription: str, context_type: str) -> str:
        """Gera laudo REAL usando GPT-4"""
        
        enhanced_prompt = f"""
{base_prompt}

DADOS COMPLETOS PARA LAUDO M√âDICO:

**ANAMNESE ESTRUTURADA:**
{anamnese}

**DADOS ORIGINAIS DO PACIENTE:**
{patient_info}

**TRANSCRI√á√ÉO ORIGINAL:**
{transcription}

**CONTEXTO:** {context_type.upper()}

DIRETRIZES ESPEC√çFICAS:
- Base o laudo na anamnese estruturada acima
- Use terminologia m√©dica apropriada para {context_type}
- Inclua CID-10 quando aplic√°vel
- Mantenha objetividade e precis√£o m√©dica
- Foque nos aspectos relevantes para o tipo de laudo
- Use apenas informa√ß√µes realmente fornecidas

Gere o laudo m√©dico especializado REAL:
"""
        
        try:
            print(f"ü§ñ Gerando laudo com GPT-4 para contexto: {context_type}")
            
            response = self.openai_client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {
                        "role": "system", 
                        "content": f"Voc√™ √© um m√©dico perito especializado em {self._get_specialty(context_type)}. Gere laudos precisos e tecnicamente corretos."
                    },
                    {
                        "role": "user", 
                        "content": enhanced_prompt
                    }
                ],
                max_tokens=2000,
                temperature=0.2
            )
            
            laudo_real = response.choices[0].message.content
            print(f"‚úÖ Laudo gerado: {len(laudo_real)} caracteres")
            
            return laudo_real
            
        except Exception as e:
            print(f"‚ùå Erro GPT laudo: {str(e)}")
            return f"""## ‚ùå ERRO NA GERA√á√ÉO DO LAUDO

**Erro:** {str(e)}

**Anamnese base:** {anamnese[:200]}...
**Contexto:** {context_type}

*Configure corretamente a chave OpenAI para funcionalidade completa*"""
    
    def _get_specialty(self, context_type: str) -> str:
        """Retorna especialidade baseada no contexto"""
        specialties = {
            'bpc': 'Medicina Legal e Per√≠cia para BPC/LOAS',
            'incapacidade': 'Medicina do Trabalho e Per√≠cia de Incapacidade',
            'pericia': 'Medicina Legal e Pericial',
            'clinica': 'Cl√≠nica M√©dica Geral'
        }
        return specialties.get(context_type, 'Cl√≠nica Geral')
