import os
import json
import asyncio
from typing import Dict, List, Optional, Any
from openai import OpenAI
import base64
from io import BytesIO
import tempfile
import faiss
import numpy as np
import pickle

class MedicalRAGService:
    def __init__(self, client, parent_service=None):
        """Inicializa o servi√ßo RAG m√©dico"""
        self.client = client
        self.parent_service = parent_service  # Refer√™ncia ao MultimodalAIService
        
        # Configura√ß√£o de embedding
        self.embedding_model = "text-embedding-3-small"
        
        # Determinar o path correto para os √≠ndices
        # Primeiro, tenta o diret√≥rio local app/index_faiss_openai
        current_dir = os.path.dirname(os.path.abspath(__file__))
        app_dir = os.path.dirname(current_dir)  # Sobe um n√≠vel para app/
        self.index_dir = os.path.join(app_dir, "index_faiss_openai")
        
        # Se n√£o existir, tenta paths alternativos
        if not os.path.exists(self.index_dir):
            # Tenta na raiz do projeto
            project_root = os.path.dirname(os.path.dirname(app_dir))
            alternative_path = os.path.join(project_root, "index_faiss_openai")
            if os.path.exists(alternative_path):
                self.index_dir = alternative_path
        
        print(f"üîç Tentando carregar √≠ndices de: {self.index_dir}")
        
        self.faiss_index = None
        self.documents = []
        self.load_indexes()
    
    def load_indexes(self):
        """Carrega os √≠ndices FAISS e documentos salvos"""
        try:
            # Verifica se o diret√≥rio existe
            if not os.path.exists(self.index_dir):
                print(f"‚ùå Diret√≥rio de √≠ndices n√£o encontrado: {self.index_dir}")
                return
            
            # Carrega o √≠ndice FAISS
            index_path = os.path.join(self.index_dir, "index.faiss")
            if os.path.exists(index_path):
                self.faiss_index = faiss.read_index(index_path)
                print(f"‚úÖ √çndice FAISS carregado: {self.faiss_index.ntotal} vetores de {index_path}")
            else:
                print(f"‚ùå Arquivo index.faiss n√£o encontrado em: {index_path}")
            
            # Carrega os documentos/chunks
            docs_path = os.path.join(self.index_dir, "documents.pkl")
            if os.path.exists(docs_path):
                with open(docs_path, 'rb') as f:
                    self.documents = pickle.load(f)
                print(f"‚úÖ Documentos carregados: {len(self.documents)} chunks de {docs_path}")
            else:
                print(f"‚ùå Arquivo documents.pkl n√£o encontrado em: {docs_path}")
                
        except Exception as e:
            print(f"‚ùå Erro ao carregar √≠ndices: {e}")
            import traceback
            traceback.print_exc()
    
    def get_rag_stats(self) -> Dict[str, Any]:
        """Retorna estat√≠sticas do sistema RAG"""
        return {
            "faiss_index_loaded": self.faiss_index is not None,
            "documents_loaded": len(self.documents) if self.documents else 0,
            "index_directory": self.index_dir,
            "vector_count": self.faiss_index.ntotal if self.faiss_index else 0
        }
    
    def get_embedding(self, text: str) -> List[float]:
        """Gera embedding para um texto usando OpenAI"""
        try:
            response = self.client.embeddings.create(
                model="text-embedding-3-small",
                input=text
            )
            return response.data[0].embedding
        except Exception as e:
            print(f"‚ùå Erro ao gerar embedding: {e}")
            return []
    
    def search_similar_documents(self, query: str, k: int = 5) -> List[tuple]:
        """Busca documentos similares no √≠ndice FAISS"""
        if not self.faiss_index or not self.documents:
            print("‚ùå √çndices n√£o carregados")
            return []
        
        try:
            # Gera embedding da query
            query_embedding = self.get_embedding(query)
            if not query_embedding:
                return []
            
            # Converte para numpy array
            query_vector = np.array([query_embedding], dtype=np.float32)
            
            # Busca no FAISS
            distances, indices = self.faiss_index.search(query_vector, k)
            
            # Retorna documentos e scores
            results = []
            for i, (distance, idx) in enumerate(zip(distances[0], indices[0])):
                if idx < len(self.documents):
                    # Converte dist√¢ncia para similaridade (maior = mais similar)
                    similarity = 1 / (1 + distance)
                    results.append((self.documents[idx], similarity))
            
            return results
            
        except Exception as e:
            print(f"‚ùå Erro na busca: {e}")
            return []
    
    def extract_patient_info(self, transcription: str) -> Dict[str, str]:
        """Extrai informa√ß√µes do paciente usando RAG + LLM"""
        
        # 1. Busca contexto relevante no RAG
        queries = [
            "nome do paciente",
            "idade do paciente", 
            "profiss√£o do paciente",
            "dados pessoais identifica√ß√£o",
            transcription[:200]  # Primeiros 200 chars da transcri√ß√£o
        ]
        
        context_docs = []
        for query in queries:
            similar_docs = self.search_similar_documents(query, k=3)
            context_docs.extend([doc for doc, score in similar_docs if score > 0.7])
        
        # Remove duplicatas
        context_docs = list(set(context_docs))
        context = "\n\n".join(context_docs[:10])  # M√°ximo 10 documentos
        
        # 2. Prompt para o LLM extrair informa√ß√µes
        prompt = f"""
Voc√™ √© um assistente m√©dico especializado em anamnese. Analise a transcri√ß√£o da consulta m√©dica e extraia as seguintes informa√ß√µes do paciente:

CONTEXTO M√âDICO RELEVANTE:
{context}

TRANSCRI√á√ÉO DA CONSULTA:
{transcription}

Extraia APENAS as seguintes informa√ß√µes se estiverem explicitamente mencionadas:
- Nome completo do paciente
- Idade 
- Profiss√£o/ocupa√ß√£o
- Queixa principal
- Sintomas relatados

Retorne no formato JSON:
{{
    "nome": "nome completo ou 'n√£o informado'",
    "idade": "idade ou 'n√£o informada'", 
    "profissao": "profiss√£o ou 'n√£o informada'",
    "queixa_principal": "queixa principal ou 'n√£o informada'",
    "sintomas": "lista de sintomas ou 'n√£o informados'"
}}

IMPORTANTE: Se uma informa√ß√£o n√£o estiver clara na transcri√ß√£o, use "n√£o informado" ou "n√£o informada".
"""

        try:
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "Voc√™ √© um assistente m√©dico especializado em extrair informa√ß√µes de anamnese. Seja preciso e objetivo."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.1,
                max_tokens=500
            )
            
            # Tenta parsear JSON
            result_text = response.choices[0].message.content.strip()
            
            # Remove markdown se houver
            if result_text.startswith('```json'):
                result_text = result_text.replace('```json', '').replace('```', '').strip()
            
            patient_info = json.loads(result_text)
            return patient_info
            
        except json.JSONDecodeError as e:
            print(f"‚ùå Erro ao parsear JSON: {e}")
            return self._extract_fallback(transcription)
        except Exception as e:
            print(f"‚ùå Erro na extra√ß√£o: {e}")
            return self._extract_fallback(transcription)
    
    def _extract_fallback(self, transcription: str) -> Dict[str, str]:
        """M√©todo de fallback para extra√ß√£o simples sem RAG"""
        try:
            prompt = f"""
Analise esta transcri√ß√£o m√©dica e extraia apenas as informa√ß√µes expl√≠citas:

{transcription[:1000]}

Retorne JSON com: nome, idade, profissao, queixa_principal, sintomas
Use "n√£o informado" se n√£o encontrar a informa√ß√£o.
"""
            
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": prompt}],
                temperature=0,
                max_tokens=300
            )
            
            result = response.choices[0].message.content.strip()
            if result.startswith('```json'):
                result = result.replace('```json', '').replace('```', '').strip()
                
            return json.loads(result)
            
        except:
            return {
                "nome": "n√£o informado",
                "idade": "n√£o informada", 
                "profissao": "n√£o informada",
                "queixa_principal": "n√£o informada",
                "sintomas": "n√£o informados"
            }

    def generate_medical_report(self, patient_text: str, patient_data: dict) -> str:
        """Gera relat√≥rio m√©dico completo com classifica√ß√£o de benef√≠cio"""
        
        # Primeiro gera a classifica√ß√£o para incluir no laudo
        benefit_classification = self.parent_service.classify_benefit_and_cid(patient_text, patient_data) if self.parent_service else {}
        
        # Montar informa√ß√µes da classifica√ß√£o para o prompt
        classification_info = ""
        if benefit_classification:
            classification_info = f"""
CLASSIFICA√á√ÉO PREVIDENCI√ÅRIA:
- Tipo de Benef√≠cio: {benefit_classification.get('tipo_beneficio', 'N√£o definido')}
- CID Principal: {benefit_classification.get('cid_principal', 'N√£o definido')} - {benefit_classification.get('cid_descricao', '')}
- Gravidade: {benefit_classification.get('gravidade', 'N√£o definida')}
- Progn√≥stico: {benefit_classification.get('progn√≥stico', 'N√£o definido')}
"""

        # Buscar casos similares no RAG primeiro
        similar_cases = []
        try:
            # Se temos uma inst√¢ncia RAG funcional, buscar casos similares
            if hasattr(self, 'search_similar_documents'):
                search_results = self.search_similar_documents(patient_text, k=3)
                # search_similar_documents retorna lista de tuplas (documento, similaridade)
                similar_cases = search_results if isinstance(search_results, list) else []
                print(f"üîç RAG encontrou {len(similar_cases)} casos similares")
        except Exception as e:
            print(f"‚ö†Ô∏è RAG n√£o dispon√≠vel: {e}")

        # Preparar contexto RAG
        rag_context = ""
        if similar_cases:
            rag_context = "\n\nCASOS SIMILARES NA BASE DE CONHECIMENTO:\n"
            for i, case_data in enumerate(similar_cases[:2], 1):
                # case_data √© uma tupla (documento, similaridade)
                case_text = case_data[0] if isinstance(case_data, tuple) else str(case_data)
                similarity = case_data[1] if isinstance(case_data, tuple) and len(case_data) > 1 else 0.0
                rag_context += f"\nCaso {i} (Similaridade: {similarity:.2f}):\n{case_text[:200]}...\n"

        prompt = f"""
Voc√™ √© um m√©dico perito previdenci√°rio experiente. Gere um LAUDO M√âDICO PROFISSIONAL seguindo a estrutura espec√≠fica abaixo.

‚ö†Ô∏è REGRAS IMPORTANTES:
- Base-se APENAS nas informa√ß√µes fornecidas pelo paciente
- N√ÉO invente exames f√≠sicos, sintomas ou detalhes n√£o relatados
- Use linguagem m√©dica t√©cnica e precisa
- Seja detalhado nos aspectos funcionais e progn√≥sticos

DADOS DO PACIENTE:
{patient_data}

INFORMA√á√ïES RELATADAS:
{patient_text}

{classification_info}

{rag_context}

ESTRUTURE O LAUDO SEGUINDO ESTE FORMATO EXATO:

**LAUDO M√âDICO PREVIDENCI√ÅRIO**

**IDENTIFICA√á√ÉO:**
Nome: {patient_data.get('nome', 'N√£o informado')}
Idade: {patient_data.get('idade', 'N√£o informada')}  
Profiss√£o: {patient_data.get('profissao', 'N√£o informada')}

**Hist√≥ria Cl√≠nica Resumida**
[UM PAR√ÅGRAFO COESO contendo: data de in√≠cio dos sintomas, evolu√ß√£o cl√≠nica, eventos de agravamento, sintomas atuais e repercuss√µes funcionais, impacto na vida di√°ria/laboral, diagn√≥stico com CID-10. Baseie-se apenas no relatado pelo paciente]

**Limita√ß√£o Funcional**
[UM PAR√ÅGRAFO descrevendo: limita√ß√µes atuais (motoras, sensoriais, cognitivas), como isso impacta a funcionalidade no trabalho/vida social/autonomia, sintomas que agravam. Use apenas informa√ß√µes relatadas]

**Tratamento**
[Descrever procedimentos, medicamentos, terapias em uso conforme relatado, resposta ou necessidade de continuidade]

**Progn√≥stico (Tend√™ncia Reservada/Desfavor√°vel)**
[Indicar evolu√ß√£o esperada, tempo estimado de afastamento se aplic√°vel, necessidade de tratamento cont√≠nuo, possibilidade de retorno √† fun√ß√£o habitual]

**Conclus√£o Congruente com o Benef√≠cio ({benefit_classification.get('tipo_beneficio', 'AN√ÅLISE_NECESS√ÅRIA')})**
[Conclus√£o espec√≠fica para o tipo de benef√≠cio:
- AUX√çLIO-DOEN√áA: incapacidade tempor√°ria, tempo estimado
- BPC/LOAS: impedimento de longo prazo, limita√ß√µes para participa√ß√£o plena
- AUX√çLIO-ACIDENTE: redu√ß√£o parcial e permanente da capacidade
- APOSENTADORIA POR INVALIDEZ: incapacidade definitiva para qualquer trabalho
- ISEN√á√ÉO IMPOSTO DE RENDA: doen√ßa grave conforme lei]

**CID-10**
{benefit_classification.get('cid_principal', 'A definir')} ‚Äì {benefit_classification.get('cid_descricao', 'Diagn√≥stico a ser confirmado')} (principal)

**DATA:** [Data atual]  
**M√âDICO RESPONS√ÅVEL:** Dr. [Nome do M√©dico]  
**CRM:** [N√∫mero do CRM]

IMPORTANTE: Crie um laudo profissional, t√©cnico e detalhado, mas baseado APENAS nas informa√ß√µes fornecidas.
"""

        try:
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "Voc√™ √© um m√©dico perito especialista em laudos previdenci√°rios. Seja t√©cnico, detalhado e preciso."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.2,
                max_tokens=2000
            )
            
            report = response.choices[0].message.content.strip()
            
            # Salvar relat√≥rio em arquivo
            patient_name = patient_data.get('nome', 'n√£o_informado').replace(' ', '_').lower()
            filename = f"relatorio_{patient_name}.txt"
            filepath = os.path.join("relatorios", filename)
            
            os.makedirs("relatorios", exist_ok=True)
            
            with open(filepath, "w", encoding="utf-8") as f:
                f.write(report)
            
            print(f"‚úÖ Relat√≥rio m√©dico completo salvo em {filepath}")
            return report
            
        except Exception as e:
            print(f"‚ùå Erro ao gerar relat√≥rio m√©dico: {e}")
            return f"Erro ao gerar relat√≥rio m√©dico: {e}"


class MultimodalAIService:
    def __init__(self):
        self.client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        
        # Inicializar RAG service com refer√™ncia a este service
        self.rag_service = MedicalRAGService(self.client, parent_service=self)
        
        # Path para salvar transcri√ß√µes
        self.relatorios_dir = "relatorios"
        self.transcription_path = os.path.join(self.relatorios_dir, "transcription.txt")
        
        # Cria diret√≥rio se n√£o existir
        os.makedirs(self.relatorios_dir, exist_ok=True)
    
    async def analyze_multimodal(self, patient_info: str = "", audio_bytes: bytes = None, image_path: str = None) -> Dict[str, Any]:
        """An√°lise multimodal com RAG integrado"""
        results = {
            "transcription": "",
            "patient_data": {},
            "medical_report": "",
            "image_analysis": "",
            "analysis": "",
            "status": "success"
        }
        
        try:
            print("üöÄ Iniciando an√°lise multimodal com RAG...")
            
            # 1. TRANSCRI√á√ÉO DE √ÅUDIO
            transcription = ""
            if audio_bytes:
                print("üéôÔ∏è Processando transcri√ß√£o de √°udio...")
                transcription = await self._transcribe_audio_whisper(audio_bytes)
                
                # Salva transcri√ß√£o em arquivo
                with open(self.transcription_path, "w", encoding="utf-8") as f:
                    f.write(transcription)
                print(f"‚úÖ Transcri√ß√£o salva em {self.transcription_path}")
                
                results["transcription"] = transcription
            
            # SEM √ÅUDIO: usar apenas se n√£o tiver patient_info
            elif not patient_info and os.path.exists(self.transcription_path):
                with open(self.transcription_path, "r", encoding="utf-8") as f:
                    transcription = f.read()
                results["transcription"] = transcription
                print(f"‚úÖ Transcri√ß√£o carregada do arquivo (sem patient_info atual)")
            
            # 2. EXTRA√á√ÉO DE DADOS DO PACIENTE COM RAG
            # PRIORIZAR TEXTO ATUAL FORNECIDO
            combined_text = ""
            if patient_info and patient_info.strip():
                print("üìù Usando texto fornecido pelo usu√°rio...")
                combined_text = patient_info.strip()
            elif transcription and not transcription.startswith("‚ö†Ô∏è") and not transcription.startswith("Erro"):
                print("üé§ Usando transcri√ß√£o de √°udio...")
                combined_text = transcription
            else:
                print("‚ö†Ô∏è Nenhum texto dispon√≠vel para an√°lise")
                combined_text = ""
            
            # Sempre tentar extrair dados se temos algum texto
            if combined_text.strip():
                patient_data = self.rag_service.extract_patient_info(combined_text)
                results["patient_data"] = patient_data
                print(f"‚úÖ Dados extra√≠dos: {patient_data}")
            else:
                print("‚ö†Ô∏è Nenhum texto dispon√≠vel para extra√ß√£o")
                results["patient_data"] = {
                    "nome": "n√£o informado",
                    "idade": "n√£o informada", 
                    "profissao": "n√£o informada",
                    "queixa_principal": "n√£o informada",
                    "sintomas": "n√£o informados"
                }
            
            # 3. GERA√á√ÉO DE RELAT√ìRIO M√âDICO COM RAG
            if combined_text.strip() and results["patient_data"]:
                print("üìã Gerando relat√≥rio m√©dico...")
                medical_report = self.rag_service.generate_medical_report(
                    combined_text, # Usar o texto combinado em vez de apenas transcri√ß√£o
                    results["patient_data"]
                )
                results["medical_report"] = medical_report
                
                # Salva relat√≥rio
                patient_name = results['patient_data'].get('nome', 'paciente')
                safe_name = patient_name.replace(' ', '_').replace('/', '_').lower()
                report_path = os.path.join(self.relatorios_dir, f"relatorio_{safe_name}.txt")
                
                with open(report_path, "w", encoding="utf-8") as f:
                    f.write(medical_report)
                print(f"‚úÖ Relat√≥rio salvo em {report_path}")
            else:
                print("‚ö†Ô∏è Dados insuficientes para gerar relat√≥rio")
            
            # 4. CLASSIFICA√á√ÉO DE BENEF√çCIO E CID
            if combined_text.strip():
                print("üè• Classificando tipo de benef√≠cio e CID...")
                benefit_classification = self.classify_benefit_and_cid(combined_text, results["patient_data"])
                results["benefit_classification"] = benefit_classification
                print(f"‚úÖ Classifica√ß√£o conclu√≠da: {benefit_classification['tipo_beneficio']}")
            else:
                print("‚ö†Ô∏è Texto insuficiente para classifica√ß√£o")
            
            # 5. AN√ÅLISE DE IMAGEM
            if image_path and os.path.exists(image_path):
                print("üñºÔ∏è Analisando imagem m√©dica...")
                image_analysis = await self._analyze_image(image_path)
                results["image_analysis"] = image_analysis
                print("‚úÖ An√°lise de imagem conclu√≠da")
            
            # 6. AN√ÅLISE INTEGRADA
            if any([results["transcription"], results["image_analysis"]]):
                print("üß† Gerando an√°lise integrada...")
                integrated_analysis = await self._generate_integrated_analysis(results)
                results["analysis"] = integrated_analysis
                print("‚úÖ An√°lise integrada conclu√≠da")
            
            print("üéâ An√°lise multimodal finalizada com sucesso!")
            return results
            
        except Exception as e:
            print(f"‚ùå Erro na an√°lise multimodal: {e}")
            results["status"] = "error"
            results["error"] = str(e)
            return results
    
    async def _transcribe_audio_whisper(self, audio_bytes: bytes) -> str:
        """Transcri√ß√£o de √°udio usando Whisper da OpenAI"""
        try:
            print(f"üéôÔ∏è Iniciando transcri√ß√£o de {len(audio_bytes)} bytes")
            
            # Salva audio temporariamente
            with tempfile.NamedTemporaryFile(delete=False, suffix=".webm") as temp_file:
                temp_file.write(audio_bytes)
                temp_file_path = temp_file.name
            
            print(f"üìÅ Arquivo tempor√°rio criado: {temp_file_path}")
            
            # Transcri√ß√£o com Whisper
            with open(temp_file_path, "rb") as audio_file:
                transcript = self.client.audio.transcriptions.create(
                    model="whisper-1",
                    file=audio_file,
                    language="pt"
                )
            
            # Remove arquivo tempor√°rio
            os.unlink(temp_file_path)
            
            transcription_text = transcript.text.strip()
            print(f"‚úÖ Transcri√ß√£o bem-sucedida: '{transcription_text[:100]}...'")
            
            return transcription_text
            
        except Exception as e:
            error_msg = str(e)
            print(f"‚ùå Erro na transcri√ß√£o: {error_msg}")
            
            # Remove arquivo tempor√°rio em caso de erro
            try:
                if 'temp_file_path' in locals():
                    os.unlink(temp_file_path)
            except:
                pass
            
            # Retorna erro mais amig√°vel
            if "format" in error_msg.lower() or "decode" in error_msg.lower():
                return "‚ö†Ô∏è Formato de √°udio n√£o suportado. Tente gravar novamente ou use as informa√ß√µes do texto."
            elif "duration" in error_msg.lower():
                return "‚ö†Ô∏è √Åudio muito curto. Grave por pelo menos 3 segundos."
            else:
                return f"‚ö†Ô∏è Erro na transcri√ß√£o do √°udio. Use as informa√ß√µes do texto."
    
    async def _analyze_image(self, image_path: str) -> str:
        """An√°lise de imagem m√©dica usando GPT-4 Vision"""
        try:
            # L√™ e codifica a imagem
            with open(image_path, "rb") as image_file:
                image_data = image_file.read()
                base64_image = base64.b64encode(image_data).decode('utf-8')
            
            # An√°lise com GPT-4 Vision
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {
                        "role": "system",
                        "content": "Voc√™ √© um m√©dico radiologista especialista. Analise a imagem m√©dica fornecida e descreva os achados de forma detalhada e profissional."
                    },
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "text",
                                "text": "Analise esta imagem m√©dica e forne√ßa uma descri√ß√£o detalhada dos achados, poss√≠veis diagn√≥sticos e recomenda√ß√µes."
                            },
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/jpeg;base64,{base64_image}"
                                }
                            }
                        ]
                    }
                ],
                temperature=0.2,
                max_tokens=1000
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            print(f"‚ùå Erro na an√°lise de imagem: {e}")
            return f"Erro na an√°lise de imagem: {e}"
    
    async def _generate_integrated_analysis(self, results: dict) -> str:
        """Gera an√°lise integrada usando RAG para contexto m√©dico"""
        
        # Busca contexto relevante baseado nos dados do paciente
        patient_data = results.get("patient_data", {})
        queries = [
            f"an√°lise m√©dica {patient_data.get('queixa_principal', '')}",
            f"diagn√≥stico {patient_data.get('sintomas', '')}",
            "avalia√ß√£o cl√≠nica consulta m√©dico"
        ]
        
        context_docs = []
        for query in queries:
            if query.strip():  # S√≥ busca se a query n√£o estiver vazia
                similar_docs = self.rag_service.search_similar_documents(query, k=3)
                context_docs.extend([doc for doc, score in similar_docs if score > 0.7])
        
        context = "\n".join(list(set(context_docs))[:5])
        
        prompt = f"""
Como m√©dico especialista, fa√ßa uma an√°lise integrada desta consulta m√©dica:

DADOS DO PACIENTE:
{json.dumps(patient_data, indent=2, ensure_ascii=False)}

TRANSCRI√á√ÉO:
{results.get('transcription', 'N√£o dispon√≠vel')[:500]}...

CONTEXTO M√âDICO RELEVANTE:
{context}

AN√ÅLISE DE IMAGEM:
{results.get('image_analysis', 'N√£o dispon√≠vel')}

Forne√ßa uma an√°lise m√©dica integrada considerando:
1. Correla√ß√£o entre sintomas e achados
2. Hip√≥teses diagn√≥sticas
3. Recomenda√ß√µes de conduta
4. Exames complementares sugeridos
5. Sinais de alerta

Seja objetivo e profissional.
"""
        
        try:
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "Voc√™ √© um m√©dico especialista fazendo an√°lise cl√≠nica integrada."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=1000
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            return f"Erro na an√°lise integrada: {e}"


    def classify_benefit_and_cid(self, patient_text: str, patient_data: dict) -> dict:
        """Classifica tipo de benef√≠cio previdenci√°rio espec√≠fico e sugere CID baseado nos dados do paciente"""
        
        prompt = f"""
Voc√™ √© um m√©dico perito especialista em classifica√ß√£o de benef√≠cios previdenci√°rios brasileiros.

DADOS DO PACIENTE:
{patient_data}

TEXTO COMPLETO DA CONSULTA:
{patient_text}

Analise os dados e classifique em um dos seguintes benef√≠cios:

1. AUX√çLIO-DOEN√áA:
   - Incapacidade tempor√°ria para trabalho (at√© 2 anos)
   - Doen√ßas agudas com recupera√ß√£o esperada
   - Fraturas, cirurgias simples, infec√ß√µes trat√°veis
   - Depress√£o leve/moderada com progn√≥stico favor√°vel

2. APOSENTADORIA POR INVALIDEZ:
   - Incapacidade total e permanente para qualquer trabalho
   - Doen√ßas cr√¥nicas degenerativas graves
   - Defici√™ncias severas irrevers√≠veis
   - Progn√≥stico sem perspectiva de melhora

3. BPC/LOAS:
   - Pessoa com defici√™ncia ou idoso (65+) em vulnerabilidade social
   - Incapacidade para vida independente e trabalho
   - Renda familiar per capita < 1/4 sal√°rio m√≠nimo
   - Defici√™ncia que cause impedimentos de longo prazo

4. AUX√çLIO-ACIDENTE:
   - Acidente de trabalho ou doen√ßa ocupacional
   - Sequela que reduza capacidade laboral
   - Redu√ß√£o da capacidade de trabalho (n√£o incapacidade total)
   - Consolida√ß√£o com sequela

5. ISEN√á√ÉO IMPOSTO DE RENDA:
   - Doen√ßas graves especificadas em lei
   - Aposentadoria por invalidez
   - Pens√£o por morte de acidente em servi√ßo p√∫blico

Retorne APENAS um JSON:
{{
    "tipo_beneficio": "AUX√çLIO-DOEN√áA" | "APOSENTADORIA POR INVALIDEZ" | "BPC/LOAS" | "AUX√çLIO-ACIDENTE" | "ISEN√á√ÉO IMPOSTO DE RENDA",
    "cid_principal": "c√≥digo CID-10",
    "cid_descricao": "descri√ß√£o do CID",
    "justificativa": "explica√ß√£o da classifica√ß√£o baseada nos crit√©rios legais",
    "gravidade": "LEVE" | "MODERADA" | "GRAVE",
    "progn√≥stico": "descri√ß√£o do progn√≥stico m√©dico"
}}
"""

        try:
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "Voc√™ √© um m√©dico perito especialista em classifica√ß√£o previdenci√°ria. Seja preciso e objetivo."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.1,
                max_tokens=500
            )
            
            result_text = response.choices[0].message.content.strip()
            
            # Remove markdown se houver
            if result_text.startswith('```json'):
                result_text = result_text.replace('```json', '').replace('```', '').strip()
            
            classification = json.loads(result_text)
            
            print(f"‚úÖ Classifica√ß√£o: {classification['tipo_beneficio']} - CID: {classification['cid_principal']}")
            return classification
            
        except Exception as e:
            print(f"‚ùå Erro na classifica√ß√£o: {e}")
            return {
                "tipo_beneficio": "ANALISE_MANUAL",
                "cid_principal": "Z00.0",
                "cid_descricao": "Exame m√©dico geral",
                "justificativa": "An√°lise manual necess√°ria",
                "gravidade": "A_DEFINIR",
                "progn√≥stico": "Avalia√ß√£o m√©dica presencial recomendada"
            }


# Fun√ß√£o de teste e demonstra√ß√£o
async def test_multimodal_service():
    """Testa o servi√ßo multimodal completo"""
    service = MultimodalAIService()
    
    # Simula uma transcri√ß√£o de teste
    test_transcription = """
    Paciente Jo√£o Silva, 45 anos, engenheiro civil. Comparece √† consulta relatando
    dor tor√°cica h√° 3 dias, tipo aperto, irradiando para bra√ßo esquerdo.
    Nega dispneia em repouso, mas refere cansa√ßo aos pequenos esfor√ßos.
    Hist√≥rico familiar de doen√ßa coronariana. Tabagista h√° 20 anos.
    Press√£o arterial: 150x95mmHg. Frequ√™ncia card√≠aca: 88bpm.
    Ausculta card√≠aca: bulhas r√≠tmicas, sem sopros.
    Solicita avalia√ß√£o cardiol√≥gica.
    """
    
    # Salva transcri√ß√£o para teste
    # service.save_transcription(test_transcription) # This line was removed as per the new_code
    
    # Executa an√°lise completa
    results = await service.analyze_multimodal()
    
    print("=== RESULTADOS DO TESTE ===")
    print(f"Transcri√ß√£o: {len(results['transcription'])} caracteres")
    print(f"Dados do paciente: {results['patient_data']}")
    print(f"Relat√≥rio m√©dico: {len(results['medical_report'])} caracteres")
    print(f"Status: {results['status']}")
    
    return results


# Exemplo de uso
if __name__ == "__main__":
    # Configura vari√°vel de ambiente se necess√°rio
    if not os.getenv('OPENAI_API_KEY'):
        print("‚ö†Ô∏è Configure a vari√°vel OPENAI_API_KEY")
    else:
        # Executa teste
        asyncio.run(test_multimodal_service())