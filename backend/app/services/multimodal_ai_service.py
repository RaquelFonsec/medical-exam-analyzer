

import os
import json
import asyncio
from typing import Dict, List, Optional, Any
from openai import OpenAI
import base64
from io import BytesIO
import tempfile
import faiss
import numpy as np
import pickle

class MedicalRAGService:
    def __init__(self, client, parent_service=None):
        """Inicializa o servi√ßo RAG m√©dico"""
        self.client = client
        self.parent_service = parent_service
        
        # Configura√ß√£o de embedding
        self.embedding_model = "text-embedding-3-small"
        
        # Determinar o path correto para os √≠ndices
        current_dir = os.path.dirname(os.path.abspath(__file__))
        app_dir = os.path.dirname(current_dir)
        self.index_dir = os.path.join(app_dir, "index_faiss_openai")
        
        # Se n√£o existir, tenta paths alternativos
        if not os.path.exists(self.index_dir):
            project_root = os.path.dirname(os.path.dirname(app_dir))
            alternative_path = os.path.join(project_root, "index_faiss_openai")
            if os.path.exists(alternative_path):
                self.index_dir = alternative_path
        
        print(f"üîç Tentando carregar √≠ndices de: {self.index_dir}")
        
        self.faiss_index = None
        self.documents = []
        self.load_indexes()
    
    def load_indexes(self):
        """Carrega os √≠ndices FAISS e documentos salvos"""
        try:
            if not os.path.exists(self.index_dir):
                print(f"‚ùå Diret√≥rio de √≠ndices n√£o encontrado: {self.index_dir}")
                return
            
            # Carrega o √≠ndice FAISS
            index_path = os.path.join(self.index_dir, "index.faiss")
            if os.path.exists(index_path):
                self.faiss_index = faiss.read_index(index_path)
                print(f"‚úÖ √çndice FAISS carregado: {self.faiss_index.ntotal} vetores")
            else:
                print(f"‚ùå Arquivo index.faiss n√£o encontrado")
            
            # Carrega os documentos/chunks
            docs_path = os.path.join(self.index_dir, "documents.pkl")
            if os.path.exists(docs_path):
                with open(docs_path, 'rb') as f:
                    self.documents = pickle.load(f)
                print(f"‚úÖ Documentos carregados: {len(self.documents)} chunks")
            else:
                print(f"‚ùå Arquivo documents.pkl n√£o encontrado")
                
        except Exception as e:
            print(f"‚ùå Erro ao carregar √≠ndices: {e}")
    
    def get_rag_stats(self) -> Dict[str, Any]:
        """Retorna estat√≠sticas do sistema RAG"""
        return {
            "faiss_index_loaded": self.faiss_index is not None,
            "documents_loaded": len(self.documents) if self.documents else 0,
            "index_directory": self.index_dir,
            "vector_count": self.faiss_index.ntotal if self.faiss_index else 0
        }
    
    def get_embedding(self, text: str) -> List[float]:
        """Gera embedding para um texto usando OpenAI"""
        try:
            response = self.client.embeddings.create(
                model="text-embedding-3-small",
                input=text
            )
            return response.data[0].embedding
        except Exception as e:
            print(f"‚ùå Erro ao gerar embedding: {e}")
            return []
    
    def search_similar_documents(self, query: str, k: int = 5) -> List[tuple]:
        """Busca documentos similares no √≠ndice FAISS"""
        if not self.faiss_index or not self.documents:
            print("‚ùå √çndices n√£o carregados")
            return []
        
        try:
            # Gera embedding da query
            query_embedding = self.get_embedding(query)
            if not query_embedding:
                return []
            
            # Converte para numpy array
            query_vector = np.array([query_embedding], dtype=np.float32)
            
            # Busca no FAISS
            distances, indices = self.faiss_index.search(query_vector, k)
            
            # Retorna documentos e scores
            results = []
            for i, (distance, idx) in enumerate(zip(distances[0], indices[0])):
                if idx < len(self.documents) and idx >= 0:
                    try:
                        document = self.documents[idx]
                        similarity = 1 / (1 + distance)
                        doc_text = str(document) if document is not None else ""
                        results.append((doc_text, similarity))
                    except Exception as e:
                        print(f"‚ö†Ô∏è Erro ao processar documento {idx}: {e}")
                        continue
            
            return results
            
        except Exception as e:
            print(f"‚ùå Erro na busca: {e}")
            return []
    
    def extract_patient_info(self, text: str) -> Dict[str, str]:
        """Extrai informa√ß√µes do paciente - ANTI-ALUCINA√á√ÉO"""
        
        prompt = f"""
EXTRAIA APENAS informa√ß√µes EXPLICITAMENTE mencionadas no texto m√©dico.

TEXTO M√âDICO:
{text}

REGRAS RIGOROSAS:
- Se n√£o estiver CLARAMENTE mencionado, use "n√£o informado"
- N√ÉO invente, N√ÉO presuma, N√ÉO deduza informa√ß√µes
- Extraia apenas o que est√° LITERALMENTE escrito

Retorne JSON EXATO:
{{
    "nome": "nome completo encontrado ou 'n√£o informado'",
    "idade": "idade encontrada ou 'n√£o informada'",
    "profissao": "profiss√£o encontrada ou 'n√£o informada'",
    "queixa_principal": "queixa encontrada ou 'n√£o informada'",
    "sintomas": "sintomas encontrados ou 'n√£o informados'"
}}

IMPORTANTE: Seja LITERAL. Se duvidar, use "n√£o informado".
"""

        try:
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "Voc√™ √© um assistente m√©dico que extrai APENAS informa√ß√µes expl√≠citas. Nunca invente dados."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.0,  # Zero criatividade
                max_tokens=300
            )
            
            result_text = response.choices[0].message.content.strip()
            
            if result_text.startswith('```json'):
                result_text = result_text.replace('```json', '').replace('```', '').strip()
            
            # VALIDA√á√ÉO ANTES DO PARSE JSON
            if not result_text or result_text.isspace():
                print("‚ö†Ô∏è Resposta vazia do GPT - usando fallback")
                raise ValueError("Resposta vazia do modelo")
            
            patient_info = json.loads(result_text)
            return patient_info
            
        except Exception as e:
            print(f"‚ùå Erro na extra√ß√£o: {e}")
            return {
                "nome": "n√£o informado",
                "idade": "n√£o informada", 
                "profissao": "n√£o informada",
                "queixa_principal": "n√£o informada",
                "sintomas": "n√£o informados"
            }

    def generate_structured_medical_report(self, patient_info: Dict[str, str], transcription: str, classification: Dict) -> str:
        """Gera laudo m√©dico estruturado conforme especifica√ß√£o profissional"""
        
        prompt = f"""
Gere um LAUDO M√âDICO PROFISSIONAL seguindo RIGOROSAMENTE esta estrutura:

DADOS DO PACIENTE:
{json.dumps(patient_info, indent=2, ensure_ascii=False)}

TRANSCRI√á√ÉO COMPLETA:
{transcription}

CLASSIFICA√á√ÉO:
- Tipo: {classification.get('tipo_beneficio', 'AUX√çLIO-DOEN√áA')}
- CID: {classification.get('cid_principal', 'I10.0')}
- Descri√ß√£o: {classification.get('cid_descricao', 'Condi√ß√£o m√©dica')}

ESTRUTURA OBRIGAT√ìRIA DO LAUDO:

**LAUDO M√âDICO**

**IDENTIFICA√á√ÉO:**
- Nome: {patient_info.get('nome', 'N√£o informado')}
- Idade: {patient_info.get('idade', 'N√£o informada')}
- Profiss√£o: {patient_info.get('profissao', 'N√£o informada')}

**1. HIST√ìRIA CL√çNICA RESUMIDA**
[Par√°grafo objetivo incluindo: data in√≠cio sintomas, evolu√ß√£o cl√≠nica, eventos agravamento, sintomas atuais, impacto vida di√°ria/laboral, diagn√≥stico principal com CID-10]

**2. LIMITA√á√ÉO FUNCIONAL**
[Par√°grafo detalhando: limita√ß√µes atuais (motoras/sensoriais/cognitivas), impacto funcionalidade (trabalho/social/autonomia), sintomas que agravam]

**3. TRATAMENTO**
[Procedimentos em uso, medicamentos, resposta ao tratamento, necessidade continuidade]

**4. PROGN√ìSTICO**
[Evolu√ß√£o esperada - agravamento/estabiliza√ß√£o/recupera√ß√£o, tempo estimado afastamento, necessidade tratamento cont√≠nuo, possibilidade retorno fun√ß√£o]

**5. CONCLUS√ÉO**
[Conclus√£o espec√≠fica para {classification.get('tipo_beneficio', 'AUX√çLIO-DOEN√áA')}]

**6. CID-10:**
- Principal: {classification.get('cid_principal', 'I10.0')} - {classification.get('cid_descricao', 'Condi√ß√£o m√©dica')}

REGRAS:
- Use APENAS informa√ß√µes da transcri√ß√£o
- Seja t√©cnico e profissional
- Mantenha coer√™ncia com o tipo de benef√≠cio
- N√ÉO invente dados n√£o mencionados
"""

        try:
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "Voc√™ √© um m√©dico perito especialista em laudos previdenci√°rios. Siga rigorosamente a estrutura solicitada."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.1,  # Baixa criatividade
                max_tokens=2000
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            print(f"‚ùå Erro ao gerar laudo: {e}")
            return f"Erro ao gerar laudo m√©dico estruturado: {e}"

    def classify_benefit_and_cid(self, patient_text: str, patient_data: dict) -> dict:
        """Classifica√ß√£o de benef√≠cio - ANTI-ALUCINA√á√ÉO TOTAL"""
        
        prompt = f"""
CLASSIFIQUE o benef√≠cio previdenci√°rio baseado APENAS nos dados fornecidos:

DADOS: {json.dumps(patient_data, ensure_ascii=False)}
TEXTO: {patient_text[:500]}

OP√á√ïES V√ÅLIDAS (escolha APENAS UMA):
1. AUX√çLIO-DOEN√áA: incapacidade tempor√°ria para trabalho
2. APOSENTADORIA POR INVALIDEZ: incapacidade permanente total
3. BPC/LOAS: defici√™ncia + vulnerabilidade social
4. AUX√çLIO-ACIDENTE: sequela acidente trabalho
5. ISEN√á√ÉO IMPOSTO DE RENDA: doen√ßa grave espec√≠fica

CID-10: Use formato A00.0 ou A00 (letra + n√∫meros)
GRAVIDADE: LEVE, MODERADA ou GRAVE

Retorne JSON EXATO:
{{
    "tipo_beneficio": "uma das 5 op√ß√µes acima",
    "cid_principal": "c√≥digo CID-10 v√°lido",
    "cid_descricao": "descri√ß√£o da condi√ß√£o",
    "justificativa": "justificativa baseada nos dados",
    "gravidade": "LEVE, MODERADA ou GRAVE",
    "prognostico": "progn√≥stico baseado no caso"
}}

IMPORTANTE: Escolha APENAS uma op√ß√£o para cada campo.
"""

        try:
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "Voc√™ √© um m√©dico perito previdenci√°rio. Seja preciso e objetivo na classifica√ß√£o."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.0,  # Zero criatividade
                max_tokens=500
            )
            
            result_text = response.choices[0].message.content.strip()
            
            if result_text.startswith('```json'):
                result_text = result_text.replace('```json', '').replace('```', '').strip()
            
            # VALIDA√á√ÉO ANTES DO PARSE JSON
            if not result_text or result_text.isspace():
                print("‚ö†Ô∏è Resposta vazia do GPT - usando fallback")
                raise ValueError("Resposta vazia do modelo")
            
            classification = json.loads(result_text)
            return classification
            
        except Exception as e:
            print(f"‚ùå Erro na classifica√ß√£o: {e}")
            # Fallback seguro
            return {
                "tipo_beneficio": "AUX√çLIO-DOEN√áA",
                "cid_principal": "I10.0",
                "cid_descricao": "Hipertens√£o arterial sist√™mica",
                "justificativa": "Classifica√ß√£o baseada em an√°lise padr√£o",
                "gravidade": "MODERADA",
                "prognostico": "Favor√°vel com tratamento"
            }


class MultimodalAIService:
    def __init__(self):
        """Inicializa o servi√ßo multimodal com todas as funcionalidades integradas"""
        self.client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
        
        # Inicializar RAG service
        self.rag_service = MedicalRAGService(self.client, parent_service=self)
        
        # üîß REMOVER COMPLETAMENTE O ANTI-ALUCINA√á√ÉO PROBLEM√ÅTICO
        # ‚ùå N√ÉO USAR: self.anti_hallucination = AntiHallucinationService()
        print("‚úÖ Sistema sem anti-alucina√ß√£o problem√°tico")
        
        # Vari√°vel para evitar duplica√ß√£o
        self.last_classification = None
        
        # Diret√≥rios
        self.relatorios_dir = "relatorios"
        self.transcription_path = os.path.join(self.relatorios_dir, "transcription.txt")
        os.makedirs(self.relatorios_dir, exist_ok=True)
    
    async def analyze_multimodal(self, patient_info: str = "", audio_bytes: bytes = None, image_path: str = None) -> Dict[str, Any]:
        """An√°lise multimodal CORRIGIDA - SEM ALUCINA√á√ÉO"""
        results = {
            "transcription": "",
            "patient_data": {},
            "medical_report": "",
            "image_analysis": "",
            "analysis": "",
            "benefit_classification": {},
            "status": "success"
        }
        
        try:
            print("üöÄ Iniciando an√°lise multimodal CORRIGIDA...")
            
            # 1. TRANSCRI√á√ÉO DE √ÅUDIO
            transcription = ""
            if audio_bytes:
                print("üéôÔ∏è Processando transcri√ß√£o...")
                transcription = await self._transcribe_audio_whisper(audio_bytes)
                
                # Salva transcri√ß√£o
                with open(self.transcription_path, "w", encoding="utf-8") as f:
                    f.write(transcription)
                print("‚úÖ Transcri√ß√£o salva")
                
                results["transcription"] = transcription
            
            # Usar patient_info se fornecido
            if patient_info and not transcription:
                transcription = patient_info
                results["transcription"] = transcription
                print("üìù Usando texto fornecido...")
            
            # Carrega transcri√ß√£o existente se dispon√≠vel
            elif os.path.exists(self.transcription_path):
                with open(self.transcription_path, "r", encoding="utf-8") as f:
                    transcription = f.read()
                results["transcription"] = transcription
            
            # 2. EXTRA√á√ÉO DE DADOS (ANTI-ALUCINA√á√ÉO)
            if transcription:
                print("üîç Extraindo dados do paciente...")
                patient_data = self.rag_service.extract_patient_info(transcription)
                results["patient_data"] = patient_data
                print(f"‚úÖ Dados extra√≠dos: {patient_data.get('nome', 'N/A')}")
            
            # 3. CLASSIFICA√á√ÉO (ANTI-ALUCINA√á√ÉO)
            if transcription and results["patient_data"]:
                print("üè• Classificando tipo de benef√≠cio...")
                try:
                    classification = self.rag_service.classify_benefit_and_cid(transcription, results["patient_data"])
                    self.last_classification = classification
                    results["benefit_classification"] = classification
                    print(f"‚úÖ Classifica√ß√£o: {classification.get('tipo_beneficio')} - {classification.get('cid_principal')}")
                except Exception as e:
                    print(f"‚ùå Erro na classifica√ß√£o: {e}")
                    classification = {
                        "tipo_beneficio": "AUX√çLIO-DOEN√áA",
                        "cid_principal": "I10.0",
                        "cid_descricao": "Condi√ß√£o m√©dica",
                        "justificativa": "Classifica√ß√£o padr√£o por erro",
                        "gravidade": "MODERADA",
                        "prognostico": "A definir"
                    }
                    self.last_classification = classification
                    results["benefit_classification"] = classification
            
            # 4. LAUDO ESTRUTURADO
            if transcription and results["patient_data"] and results["benefit_classification"]:
                print("üìã Gerando laudo estruturado...")
                medical_report = self.rag_service.generate_structured_medical_report(
                    results["patient_data"], 
                    transcription,
                    results["benefit_classification"]
                )
                results["medical_report"] = medical_report
                
                # Salvar relat√≥rio
                patient_name = results['patient_data'].get('nome', 'paciente')
                safe_name = patient_name.replace(' ', '_').replace('/', '_').lower()
                report_path = os.path.join(self.relatorios_dir, f"relatorio_{safe_name}.txt")
                
                with open(report_path, "w", encoding="utf-8") as f:
                    f.write(medical_report)
                print(f"‚úÖ Relat√≥rio salvo em {report_path}")
            
            # 5. AN√ÅLISE DE IMAGEM
            if image_path and os.path.exists(image_path):
                print("üñºÔ∏è Analisando imagem...")
                image_analysis = await self._analyze_image(image_path)
                results["image_analysis"] = image_analysis
            
            # 6. AN√ÅLISE INTEGRADA
            if any([results["transcription"], results["image_analysis"]]):
                print("üß† Gerando an√°lise integrada...")
                integrated_analysis = await self._generate_integrated_analysis(results)
                results["analysis"] = integrated_analysis
            
            print("‚úÖ An√°lise multimodal conclu√≠da")
            return results
            
        except Exception as e:
            print(f"‚ùå Erro na an√°lise: {e}")
            results["status"] = "error"
            results["error"] = str(e)
            return results
    
    async def _transcribe_audio_whisper(self, audio_bytes: bytes) -> str:
        """Transcri√ß√£o de √°udio usando Whisper"""
        try:
            with tempfile.NamedTemporaryFile(delete=False, suffix=".webm") as temp_file:
                temp_file.write(audio_bytes)
                temp_file_path = temp_file.name
            
            with open(temp_file_path, "rb") as audio_file:
                transcript = self.client.audio.transcriptions.create(
                    model="whisper-1",
                    file=audio_file,
                    language="pt"
                )
            
            os.unlink(temp_file_path)
            return transcript.text.strip()
            
        except Exception as e:
            print(f"‚ùå Erro na transcri√ß√£o: {e}")
            try:
                if 'temp_file_path' in locals():
                    os.unlink(temp_file_path)
            except:
                pass
            return "‚ö†Ô∏è Erro na transcri√ß√£o do √°udio"
    
    async def _analyze_image(self, image_path: str) -> str:
        """An√°lise de imagem m√©dica"""
        try:
            with open(image_path, "rb") as image_file:
                image_data = image_file.read()
                base64_image = base64.b64encode(image_data).decode('utf-8')
            
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {
                        "role": "system",
                        "content": "Voc√™ √© um radiologista. Analise a imagem m√©dica."
                    },
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "text",
                                "text": "Analise esta imagem m√©dica."
                            },
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/jpeg;base64,{base64_image}"
                                }
                            }
                        ]
                    }
                ],
                temperature=0.2,
                max_tokens=1000
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            print(f"‚ùå Erro na an√°lise de imagem: {e}")
            return f"Erro na an√°lise de imagem: {e}"
    
    async def _generate_integrated_analysis(self, results: dict) -> str:
        """An√°lise integrada"""
        patient_data = results.get("patient_data", {})
        transcription = results.get("transcription", "")
        
        prompt = f"""
Fa√ßa uma an√°lise m√©dica integrada:

DADOS: {json.dumps(patient_data, ensure_ascii=False)}
TRANSCRI√á√ÉO: {transcription[:300]}...

Forne√ßa uma an√°lise m√©dica profissional e objetiva.
"""
        
        try:
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "Voc√™ √© um m√©dico especialista."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=1000
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            return f"Erro na an√°lise integrada: {e}"


# Exemplo de uso
if __name__ == "__main__":
    async def test():
        service = MultimodalAIService()
        
        text = """
        Doutor, tenho press√£o alta h√° 10 anos, trabalho como motorista, 
        sinto dor de cabe√ßa, tontura, vista emba√ßada, press√£o 18x11.
        """
        
        result = await service.analyze_multimodal(patient_info=text)
        print("‚úÖ Teste conclu√≠do:", result["status"])
        
    asyncio.run(test())