"""
Pipeline Principal de AnÃ¡lise MÃ©dica com LangGraph
"""

import asyncio
from datetime import datetime
from typing import Dict, List, Any, Tuple

# ImportaÃ§Ãµes LangGraph
try:
    from langgraph.graph import StateGraph, START, END
    from langgraph.checkpoint.memory import MemorySaver
    LANGGRAPH_IMPORTS_OK = True
except ImportError as e:
    print(f"âŒ Erro nas importaÃ§Ãµes LangGraph: {e}")
    LANGGRAPH_IMPORTS_OK = False

from ..models.state_models import MedicalAnalysisState
from ..models.pydantic_models import CompleteMedicalRecord
from ..nodes.medical_nodes import MedicalAnalysisNodes

class MedicalAnalysisPipeline:
    """Pipeline completo de anÃ¡lise mÃ©dica com LangGraph"""
    
    def __init__(self, client, rag_service):
        self.client = client
        self.rag_service = rag_service
        self.nodes = MedicalAnalysisNodes(client, rag_service)
        self.graph = self._build_graph()
        
        # ConfiguraÃ§Ãµes do pipeline
        self.pipeline_config = {
            "max_retries": 3,
            "timeout_seconds": 300,
            "enable_checkpoints": True,
            "log_level": "INFO"
        }
        
        # MÃ©tricas de performance
        self.metrics = {
            "total_analyses": 0,
            "successful_analyses": 0,
            "failed_analyses": 0,
            "average_processing_time": 0.0,
            "specialty_distribution": {},
            "benefit_classification_stats": {}
        }
    
    def _build_graph(self) -> StateGraph:
        """ConstrÃ³i o grafo do pipeline"""
        
        # Verificar se LangGraph estÃ¡ disponÃ­vel
        if not LANGGRAPH_IMPORTS_OK:
            raise ImportError("LangGraph nÃ£o estÃ¡ disponÃ­vel. Instale com: pip install langgraph")
        
        # Criar grafo com estado tipado
        workflow = StateGraph(MedicalAnalysisState)
        
        # Adicionar nodos com validaÃ§Ãµes
        workflow.add_node("extract_basic", self._wrap_node_with_error_handling(
            self.nodes.extract_basic_data, "ExtraÃ§Ã£o de dados bÃ¡sicos"
        ))
        workflow.add_node("analyze_specialty", self._wrap_node_with_error_handling(
            self.nodes.analyze_by_specialty, "AnÃ¡lise por especialidade"
        ))
        workflow.add_node("detect_occupational", self._wrap_node_with_error_handling(
            self.nodes.detect_occupational_nexus, "DetecÃ§Ã£o de nexo ocupacional"
        ))
        workflow.add_node("classify_benefit", self._wrap_node_with_error_handling(
            self.nodes.classify_benefit, "ClassificaÃ§Ã£o de benefÃ­cio"
        ))
        workflow.add_node("generate_record", self._wrap_node_with_error_handling(
            self.nodes.generate_medical_record, "GeraÃ§Ã£o de prontuÃ¡rio"
        ))
        workflow.add_node("generate_report", self._wrap_node_with_error_handling(
            self.nodes.generate_final_report, "GeraÃ§Ã£o de laudo final"
        ))
        
        # Definir fluxo sequencial com condicionais
        workflow.add_edge(START, "extract_basic")
        workflow.add_conditional_edges(
            "extract_basic",
            self._should_continue_after_extraction,
            {
                "continue": "analyze_specialty",
                "error": END
            }
        )
        workflow.add_edge("analyze_specialty", "detect_occupational")
        workflow.add_edge("detect_occupational", "classify_benefit")
        workflow.add_conditional_edges(
            "classify_benefit",
            self._should_generate_full_record,
            {
                "full_record": "generate_record",
                "simple_report": "generate_report"
            }
        )
        workflow.add_edge("generate_record", "generate_report")
        workflow.add_edge("generate_report", END)
        
        # Compilar com checkpointer para debugging e recuperaÃ§Ã£o
        if self.pipeline_config["enable_checkpoints"]:
            memory = MemorySaver()
            compiled_graph = workflow.compile(checkpointer=memory)
        else:
            compiled_graph = workflow.compile()
        
        print("âœ… Grafo LangGraph construÃ­do com sucesso")
        return compiled_graph
    
    def _wrap_node_with_error_handling(self, node_func, node_name: str):
        """Wraps node function with error handling and metrics"""
        async def wrapped_node(state: MedicalAnalysisState) -> MedicalAnalysisState:
            start_time = datetime.now()
            
            try:
                print(f"ðŸ”„ Executando: {node_name}")
                result_state = await node_func(state)
                
                # Log sucesso
                processing_time = (datetime.now() - start_time).total_seconds()
                print(f"âœ… {node_name} concluÃ­do em {processing_time:.2f}s")
                
                return result_state
                
            except Exception as e:
                # Log erro
                error_msg = f"Erro em {node_name}: {str(e)}"
                print(f"âŒ {error_msg}")
                
                # Adicionar erro ao estado
                if "errors" not in state:
                    state["errors"] = []
                state["errors"].append(error_msg)
                state["current_step"] = f"error_in_{node_name.lower().replace(' ', '_')}"
                
                return state
        
        return wrapped_node
    
    def _should_continue_after_extraction(self, state: MedicalAnalysisState) -> str:
        """Decide se deve continuar apÃ³s extraÃ§Ã£o bÃ¡sica"""
        if state.get("errors") and len(state["errors"]) > 0:
            return "error"
        
        extracted_data = state.get("extracted_data")
        if not extracted_data or not extracted_data.get("identificacao"):
            return "error"
        
        return "continue"
    
    def _should_generate_full_record(self, state: MedicalAnalysisState) -> str:
        """Decide se deve gerar prontuÃ¡rio completo ou apenas relatÃ³rio simples"""
        # Se hÃ¡ muitos erros, gerar apenas relatÃ³rio simples
        if state.get("errors") and len(state["errors"]) > 2:
            return "simple_report"
        
        # Se classificaÃ§Ã£o foi bem-sucedida, gerar prontuÃ¡rio completo
        classification = state.get("benefit_classification")
        if classification and classification.get("tipo_beneficio"):
            return "full_record"
        
        return "simple_report"
    
    async def analyze_medical_case(self, patient_text: str) -> Tuple[CompleteMedicalRecord, str]:
        """Executa anÃ¡lise completa do caso mÃ©dico"""
        
        analysis_start_time = datetime.now()
        analysis_id = f"analysis_{int(analysis_start_time.timestamp())}"
        
        print(f"ðŸš€ INICIANDO PIPELINE DE ANÃLISE MÃ‰DICA - ID: {analysis_id}")
        print(f"ðŸ“„ Texto de entrada: {len(patient_text)} caracteres")
        
        # Atualizar mÃ©tricas
        self.metrics["total_analyses"] += 1
        
        # Estado inicial com metadados
        initial_state = MedicalAnalysisState(
            original_text=patient_text,
            extracted_data=None,
            medical_record=None,
            benefit_classification=None,
            specialist_analysis=None,
            final_report=None,
            errors=[],
            current_step="pipeline_starting"
        )
        
        try:
            # ConfiguraÃ§Ã£o da execuÃ§Ã£o
            config = {
                "configurable": {
                    "thread_id": analysis_id,
                    "run_name": f"medical_analysis_{analysis_id}",
                    "tags": ["medical_analysis", "telemedicine"]
                }
            }
            
            # Executar pipeline com timeout
            print("âš¡ Executando pipeline LangGraph...")
            
            if self.pipeline_config["timeout_seconds"]:
                final_state = await asyncio.wait_for(
                    self.graph.ainvoke(initial_state, config),
                    timeout=self.pipeline_config["timeout_seconds"]
                )
            else:
                final_state = await self.graph.ainvoke(initial_state, config)
            
            # Calcular tempo de processamento
            processing_time = (datetime.now() - analysis_start_time).total_seconds()
            
            # Verificar resultado
            if final_state.get("errors") and len(final_state["errors"]) > 0:
                print(f"âš ï¸  Pipeline concluÃ­do com {len(final_state['errors'])} erro(s):")
                for error in final_state["errors"]:
                    print(f"   - {error}")
                
                self._update_error_metrics(final_state["errors"])
            else:
                print("âœ… Pipeline executado sem erros")
                self.metrics["successful_analyses"] += 1
            
            # Extrair resultados
            medical_record = final_state.get("medical_record")
            final_report = final_state.get("final_report", "")
            
            # Se nÃ£o hÃ¡ relatÃ³rio, gerar um bÃ¡sico
            if not final_report:
                final_report = self._generate_fallback_report(final_state, patient_text)
            
            # Atualizar mÃ©tricas de performance
            self._update_performance_metrics(final_state, processing_time)
            
            # Log final
            print(f"ðŸ PIPELINE CONCLUÃDO - Etapa final: {final_state.get('current_step', 'unknown')}")
            print(f"â±ï¸  Tempo total: {processing_time:.2f}s")
            
            if final_state.get("benefit_classification"):
                benefit_type = final_state["benefit_classification"].get("tipo_beneficio", "NÃƒO_CLASSIFICADO")
                print(f"ðŸŽ¯ BenefÃ­cio classificado: {benefit_type}")
            
            return medical_record, final_report
            
        except asyncio.TimeoutError:
            error_msg = f"Pipeline excedeu timeout de {self.pipeline_config['timeout_seconds']}s"
            print(f"â° {error_msg}")
            self.metrics["failed_analyses"] += 1
            
            fallback_report = f"ANÃLISE INTERROMPIDA POR TIMEOUT\n\n{error_msg}\n\nTexto analisado parcialmente."
            return None, fallback_report
            
        except Exception as e:
            error_msg = f"Erro crÃ­tico no pipeline: {str(e)}"
            print(f"ðŸ’¥ {error_msg}")
            self.metrics["failed_analyses"] += 1
            
            import traceback
            print(f"Stack trace: {traceback.format_exc()}")
            
            error_report = f"ERRO NO PROCESSAMENTO\n\n{error_msg}\n\nPor favor, verifique o texto de entrada e tente novamente."
            return None, error_report
    
    def _update_error_metrics(self, errors: List[str]):
        """Atualiza mÃ©tricas de erro"""
        self.metrics["failed_analyses"] += 1
        
        for error in errors:
            if "extraÃ§Ã£o" in error.lower():
                self.metrics.setdefault("extraction_errors", 0)
                self.metrics["extraction_errors"] += 1
            elif "classificaÃ§Ã£o" in error.lower():
                self.metrics.setdefault("classification_errors", 0)
                self.metrics["classification_errors"] += 1
            elif "especialidade" in error.lower():
                self.metrics.setdefault("specialty_errors", 0)
                self.metrics["specialty_errors"] += 1
    
    def _update_performance_metrics(self, final_state: MedicalAnalysisState, processing_time: float):
        """Atualiza mÃ©tricas de performance"""
        
        total_analyses = self.metrics["total_analyses"]
        current_avg = self.metrics["average_processing_time"]
        
        self.metrics["average_processing_time"] = (
            (current_avg * (total_analyses - 1) + processing_time) / total_analyses
        )
        
        specialist_analysis = final_state.get("specialist_analysis", {})
        if specialist_analysis.get("primary_specialty"):
            specialty = specialist_analysis["primary_specialty"]
            specialty_name = specialty.value if hasattr(specialty, 'value') else str(specialty)
            
            self.metrics["specialty_distribution"].setdefault(specialty_name, 0)
            self.metrics["specialty_distribution"][specialty_name] += 1
        
        classification = final_state.get("benefit_classification", {})
        if classification.get("tipo_beneficio"):
            benefit_type = classification["tipo_beneficio"]
            
            self.metrics["benefit_classification_stats"].setdefault(benefit_type, 0)
            self.metrics["benefit_classification_stats"][benefit_type] += 1
    
    def _generate_fallback_report(self, state: MedicalAnalysisState, original_text: str) -> str:
        """Gera relatÃ³rio de fallback quando o pipeline falha"""
        
        return f"""
RELATÃ“RIO MÃ‰DICO PARCIAL

âš ï¸  ATENÃ‡ÃƒO: AnÃ¡lise incompleta devido a erro no processamento

DADOS COLETADOS:
- Texto original: {len(original_text)} caracteres
- Etapa atual: {state.get('current_step', 'desconhecida')}
- Erros encontrados: {len(state.get('errors', []))}

ERROS IDENTIFICADOS:
{chr(10).join([f"â€¢ {error}" for error in state.get('errors', [])])}

RECOMENDAÃ‡ÃƒO:
Este caso requer revisÃ£o manual devido aos erros encontrados no processamento automÃ¡tico.

Data do processamento: {datetime.now().strftime("%d/%m/%Y %H:%M:%S")}
"""
   
    def get_pipeline_metrics(self) -> Dict[str, Any]:
        """Retorna mÃ©tricas do pipeline"""
        return {
            **self.metrics,
            "success_rate": (
                self.metrics["successful_analyses"] / max(self.metrics["total_analyses"], 1) * 100
            ),
            "error_rate": (
                self.metrics["failed_analyses"] / max(self.metrics["total_analyses"], 1) * 100
            ),
            "configuration": self.pipeline_config
        }
    
    def reset_metrics(self):
        """Reseta mÃ©tricas do pipeline"""
        self.metrics = {
            "total_analyses": 0,
            "successful_analyses": 0,
            "failed_analyses": 0,
            "average_processing_time": 0.0,
            "specialty_distribution": {},
            "benefit_classification_stats": {}
        }
        print("ðŸ“Š MÃ©tricas do pipeline resetadas")
