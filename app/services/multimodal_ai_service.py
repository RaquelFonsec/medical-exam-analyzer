import os
import json
import asyncio
from typing import Dict, List, Optional, Any
from openai import OpenAI
import base64
from io import BytesIO
import tempfile
import faiss
import numpy as np
import pickle

class MedicalRAGService:
    def __init__(self):
        self.client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
        self.index_dir = "index_faiss_openai"
        self.faiss_index = None
        self.documents = []
        self.load_indexes()
    
    def load_indexes(self):
        """Carrega os √≠ndices FAISS e documentos salvos"""
        try:
            # Carrega o √≠ndice FAISS
            index_path = os.path.join(self.index_dir, "index.faiss")
            if os.path.exists(index_path):
                self.faiss_index = faiss.read_index(index_path)
                print(f"‚úÖ √çndice FAISS carregado: {self.faiss_index.ntotal} vetores")
            
            # Carrega os documentos/chunks
            docs_path = os.path.join(self.index_dir, "documents.pkl")
            if os.path.exists(docs_path):
                with open(docs_path, 'rb') as f:
                    self.documents = pickle.load(f)
                print(f"‚úÖ Documentos carregados: {len(self.documents)} chunks")
                
        except Exception as e:
            print(f"‚ùå Erro ao carregar √≠ndices: {e}")
    
    def get_embedding(self, text: str) -> List[float]:
        """Gera embedding para um texto usando OpenAI"""
        try:
            response = self.client.embeddings.create(
                model="text-embedding-3-small",
                input=text
            )
            return response.data[0].embedding
        except Exception as e:
            print(f"‚ùå Erro ao gerar embedding: {e}")
            return []
    
    def search_similar_documents(self, query: str, k: int = 5) -> List[tuple]:
        """Busca documentos similares no √≠ndice FAISS"""
        if not self.faiss_index or not self.documents:
            print("‚ùå √çndices n√£o carregados")
            return []
        
        try:
            # Gera embedding da query
            query_embedding = self.get_embedding(query)
            if not query_embedding:
                return []
            
            # Converte para numpy array
            query_vector = np.array([query_embedding], dtype=np.float32)
            
            # Busca no FAISS
            distances, indices = self.faiss_index.search(query_vector, k)
            
            # Retorna documentos e scores
            results = []
            for i, (distance, idx) in enumerate(zip(distances[0], indices[0])):
                if idx < len(self.documents):
                    # Converte dist√¢ncia para similaridade (maior = mais similar)
                    similarity = 1 / (1 + distance)
                    results.append((self.documents[idx], similarity))
            
            return results
            
        except Exception as e:
            print(f"‚ùå Erro na busca: {e}")
            return []
    
    def extract_patient_info(self, transcription: str) -> Dict[str, str]:
        """Extrai informa√ß√µes do paciente usando RAG + LLM"""
        
        # 1. Busca contexto relevante no RAG
        queries = [
            "nome do paciente",
            "idade do paciente", 
            "profiss√£o do paciente",
            "dados pessoais identifica√ß√£o",
            transcription[:200]  # Primeiros 200 chars da transcri√ß√£o
        ]
        
        context_docs = []
        for query in queries:
            similar_docs = self.search_similar_documents(query, k=3)
            context_docs.extend([doc for doc, score in similar_docs if score > 0.7])
        
        # Remove duplicatas
        context_docs = list(set(context_docs))
        context = "\n\n".join(context_docs[:10])  # M√°ximo 10 documentos
        
        # 2. Prompt para o LLM extrair informa√ß√µes
        prompt = f"""
Voc√™ √© um assistente m√©dico especializado em anamnese. Analise a transcri√ß√£o da consulta m√©dica e extraia as seguintes informa√ß√µes do paciente:

CONTEXTO M√âDICO RELEVANTE:
{context}

TRANSCRI√á√ÉO DA CONSULTA:
{transcription}

Extraia APENAS as seguintes informa√ß√µes se estiverem explicitamente mencionadas:
- Nome completo do paciente
- Idade 
- Profiss√£o/ocupa√ß√£o
- Queixa principal
- Sintomas relatados

Retorne no formato JSON:
{{
    "nome": "nome completo ou 'n√£o informado'",
    "idade": "idade ou 'n√£o informada'", 
    "profissao": "profiss√£o ou 'n√£o informada'",
    "queixa_principal": "queixa principal ou 'n√£o informada'",
    "sintomas": "lista de sintomas ou 'n√£o informados'"
}}

IMPORTANTE: Se uma informa√ß√£o n√£o estiver clara na transcri√ß√£o, use "n√£o informado" ou "n√£o informada".
"""

        try:
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "Voc√™ √© um assistente m√©dico especializado em extrair informa√ß√µes de anamnese. Seja preciso e objetivo."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.1,
                max_tokens=500
            )
            
            # Tenta parsear JSON
            result_text = response.choices[0].message.content.strip()
            
            # Remove markdown se houver
            if result_text.startswith('```json'):
                result_text = result_text.replace('```json', '').replace('```', '').strip()
            
            patient_info = json.loads(result_text)
            return patient_info
            
        except json.JSONDecodeError as e:
            print(f"‚ùå Erro ao parsear JSON: {e}")
            return self._extract_fallback(transcription)
        except Exception as e:
            print(f"‚ùå Erro na extra√ß√£o: {e}")
            return self._extract_fallback(transcription)
    
    def _extract_fallback(self, transcription: str) -> Dict[str, str]:
        """M√©todo de fallback para extra√ß√£o simples sem RAG"""
        try:
            prompt = f"""
Analise esta transcri√ß√£o m√©dica e extraia apenas as informa√ß√µes expl√≠citas:

{transcription[:1000]}

Retorne JSON com: nome, idade, profissao, queixa_principal, sintomas
Use "n√£o informado" se n√£o encontrar a informa√ß√£o.
"""
            
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": prompt}],
                temperature=0,
                max_tokens=300
            )
            
            result = response.choices[0].message.content.strip()
            if result.startswith('```json'):
                result = result.replace('```json', '').replace('```', '').strip()
                
            return json.loads(result)
            
        except:
            return {
                "nome": "n√£o informado",
                "idade": "n√£o informada", 
                "profissao": "n√£o informada",
                "queixa_principal": "n√£o informada",
                "sintomas": "n√£o informados"
            }

    def generate_medical_report(self, patient_info: Dict[str, str], transcription: str) -> str:
        """Gera relat√≥rio m√©dico estruturado"""
        
        # Busca contexto relevante para o relat√≥rio
        context_queries = [
            f"relat√≥rio m√©dico {patient_info.get('queixa_principal', '')}",
            f"exame cl√≠nico {patient_info.get('sintomas', '')}",
            "estrutura relat√≥rio m√©dico",
            "anamnese consulta m√©dica"
        ]
        
        context_docs = []
        for query in context_queries:
            similar_docs = self.search_similar_documents(query, k=2)
            context_docs.extend([doc for doc, score in similar_docs if score > 0.6])
        
        context = "\n".join(list(set(context_docs))[:8])
        
        prompt = f"""
Com base na transcri√ß√£o da consulta m√©dica, gere um relat√≥rio m√©dico estruturado e profissional.

INFORMA√á√ïES DO PACIENTE:
{json.dumps(patient_info, indent=2, ensure_ascii=False)}

CONTEXTO M√âDICO RELEVANTE:
{context}

TRANSCRI√á√ÉO COMPLETA:
{transcription}

Gere um relat√≥rio m√©dico seguindo esta estrutura:

**RELAT√ìRIO M√âDICO**

**IDENTIFICA√á√ÉO DO PACIENTE:**
- Nome: {patient_info.get('nome', 'N√£o informado')}
- Idade: {patient_info.get('idade', 'N√£o informada')}
- Profiss√£o: {patient_info.get('profissao', 'N√£o informada')}

**ANAMNESE:**
- Queixa Principal: 
- Hist√≥ria da Doen√ßa Atual:
- Sintomas e Sinais:

**EXAME CL√çNICO:**
[Descreva os achados do exame f√≠sico mencionados]

**HIP√ìTESE DIAGN√ìSTICA:**
[Baseado nos sintomas relatados]

**CONDUTA/PLANO:**
[Tratamento, exames solicitados, orienta√ß√µes]

**OBSERVA√á√ïES:**
[Informa√ß√µes adicionais relevantes]

Seja profissional, claro e baseie-se apenas nas informa√ß√µes fornecidas na transcri√ß√£o.
"""

        try:
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "Voc√™ √© um m√©dico especialista em elaborar relat√≥rios m√©dicos estruturados e profissionais."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.2,
                max_tokens=1500
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            print(f"‚ùå Erro ao gerar relat√≥rio: {e}")
            return f"Erro ao gerar relat√≥rio m√©dico: {e}"


class MultimodalAIService:
    def __init__(self):
        self.client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
        self.rag_service = MedicalRAGService()  # Nova inst√¢ncia do RAG
        
        # Configura√ß√£o de caminhos
        self.relatorios_dir = "relatorios"
        self.transcription_path = os.path.join(self.relatorios_dir, "transcription.txt")
        
        # Cria diret√≥rio se n√£o existir
        os.makedirs(self.relatorios_dir, exist_ok=True)
    
    async def analyze_multimodal(self, patient_info: str = "", audio_bytes: bytes = None, image_path: str = None) -> Dict[str, Any]:
        """An√°lise multimodal com RAG integrado"""
        results = {
            "transcription": "",
            "patient_data": {},
            "medical_report": "",
            "image_analysis": "",
            "analysis": "",
            "status": "success"
        }
        
        try:
            print("üöÄ Iniciando an√°lise multimodal com RAG...")
            
            # 1. TRANSCRI√á√ÉO DE √ÅUDIO
            transcription = ""
            if audio_bytes:
                print("üéôÔ∏è Processando transcri√ß√£o de √°udio...")
                transcription = await self._transcribe_audio_whisper(audio_bytes)
                
                # Salva transcri√ß√£o em arquivo
                with open(self.transcription_path, "w", encoding="utf-8") as f:
                    f.write(transcription)
                print(f"‚úÖ Transcri√ß√£o salva em {self.transcription_path}")
                
                results["transcription"] = transcription
            
            # Carrega transcri√ß√£o existente se n√£o houver √°udio
            elif os.path.exists(self.transcription_path):
                with open(self.transcription_path, "r", encoding="utf-8") as f:
                    transcription = f.read()
                results["transcription"] = transcription
                print(f"‚úÖ Transcri√ß√£o carregada do arquivo existente")
            
            # 2. EXTRA√á√ÉO DE DADOS DO PACIENTE COM RAG
            if transcription:
                print("üîç Extraindo informa√ß√µes do paciente com RAG...")
                patient_data = self.rag_service.extract_patient_info(transcription)
                results["patient_data"] = patient_data
                print(f"‚úÖ Dados extra√≠dos: {patient_data}")
            
            # 3. GERA√á√ÉO DE RELAT√ìRIO M√âDICO COM RAG
            if transcription and results["patient_data"]:
                print("üìã Gerando relat√≥rio m√©dico...")
                medical_report = self.rag_service.generate_medical_report(
                    results["patient_data"], 
                    transcription
                )
                results["medical_report"] = medical_report
                
                # Salva relat√≥rio
                patient_name = results['patient_data'].get('nome', 'paciente')
                safe_name = patient_name.replace(' ', '_').replace('/', '_').lower()
                report_path = os.path.join(self.relatorios_dir, f"relatorio_{safe_name}.txt")
                
                with open(report_path, "w", encoding="utf-8") as f:
                    f.write(medical_report)
                print(f"‚úÖ Relat√≥rio salvo em {report_path}")
            
            # 4. AN√ÅLISE DE IMAGEM
            if image_path and os.path.exists(image_path):
                print("üñºÔ∏è Analisando imagem m√©dica...")
                image_analysis = await self._analyze_image(image_path)
                results["image_analysis"] = image_analysis
                print("‚úÖ An√°lise de imagem conclu√≠da")
            
            # 5. AN√ÅLISE INTEGRADA
            if any([results["transcription"], results["image_analysis"]]):
                print("üß† Gerando an√°lise integrada...")
                integrated_analysis = await self._generate_integrated_analysis(results)
                results["analysis"] = integrated_analysis
                print("‚úÖ An√°lise integrada conclu√≠da")
            
            print("üéâ An√°lise multimodal finalizada com sucesso!")
            return results
            
        except Exception as e:
            print(f"‚ùå Erro na an√°lise multimodal: {e}")
            results["status"] = "error"
            results["error"] = str(e)
            return results
    
    async def _transcribe_audio_whisper(self, audio_bytes: bytes) -> str:
        """Transcri√ß√£o de √°udio usando Whisper da OpenAI"""
        try:
            # Salva audio temporariamente
            with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as temp_file:
                temp_file.write(audio_bytes)
                temp_file_path = temp_file.name
            
            # Transcri√ß√£o com Whisper
            with open(temp_file_path, "rb") as audio_file:
                transcript = self.client.audio.transcriptions.create(
                    model="whisper-1",
                    file=audio_file,
                    language="pt"
                )
            
            # Remove arquivo tempor√°rio
            os.unlink(temp_file_path)
            
            return transcript.text
            
        except Exception as e:
            print(f"‚ùå Erro na transcri√ß√£o: {e}")
            return f"Erro na transcri√ß√£o: {e}"
    
    async def _analyze_image(self, image_path: str) -> str:
        """An√°lise de imagem m√©dica usando GPT-4 Vision"""
        try:
            # L√™ e codifica a imagem
            with open(image_path, "rb") as image_file:
                image_data = image_file.read()
                base64_image = base64.b64encode(image_data).decode('utf-8')
            
            # An√°lise com GPT-4 Vision
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {
                        "role": "system",
                        "content": "Voc√™ √© um m√©dico radiologista especialista. Analise a imagem m√©dica fornecida e descreva os achados de forma detalhada e profissional."
                    },
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "text",
                                "text": "Analise esta imagem m√©dica e forne√ßa uma descri√ß√£o detalhada dos achados, poss√≠veis diagn√≥sticos e recomenda√ß√µes."
                            },
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/jpeg;base64,{base64_image}"
                                }
                            }
                        ]
                    }
                ],
                temperature=0.2,
                max_tokens=1000
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            print(f"‚ùå Erro na an√°lise de imagem: {e}")
            return f"Erro na an√°lise de imagem: {e}"
    
    async def _generate_integrated_analysis(self, results: dict) -> str:
        """Gera an√°lise integrada usando RAG para contexto m√©dico"""
        
        # Busca contexto relevante baseado nos dados do paciente
        patient_data = results.get("patient_data", {})
        queries = [
            f"an√°lise m√©dica {patient_data.get('queixa_principal', '')}",
            f"diagn√≥stico {patient_data.get('sintomas', '')}",
            "avalia√ß√£o cl√≠nica consulta m√©dica"
        ]
        
        context_docs = []
        for query in queries:
            if query.strip():  # S√≥ busca se a query n√£o estiver vazia
                similar_docs = self.rag_service.search_similar_documents(query, k=3)
                context_docs.extend([doc for doc, score in similar_docs if score > 0.7])
        
        context = "\n".join(list(set(context_docs))[:5])
        
        prompt = f"""
Como m√©dico especialista, fa√ßa uma an√°lise integrada desta consulta m√©dica:

DADOS DO PACIENTE:
{json.dumps(patient_data, indent=2, ensure_ascii=False)}

TRANSCRI√á√ÉO:
{results.get('transcription', 'N√£o dispon√≠vel')[:500]}...

CONTEXTO M√âDICO RELEVANTE:
{context}

AN√ÅLISE DE IMAGEM:
{results.get('image_analysis', 'N√£o dispon√≠vel')}

Forne√ßa uma an√°lise m√©dica integrada considerando:
1. Correla√ß√£o entre sintomas e achados
2. Hip√≥teses diagn√≥sticas
3. Recomenda√ß√µes de conduta
4. Exames complementares sugeridos
5. Sinais de alerta

Seja objetivo e profissional.
"""
        
        try:
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "Voc√™ √© um m√©dico especialista fazendo an√°lise cl√≠nica integrada."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=1000
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            return f"Erro na an√°lise integrada: {e}"

    # M√©todos auxiliares
    def get_transcription(self) -> str:
        """Retorna a transcri√ß√£o salva"""
        if os.path.exists(self.transcription_path):
            with open(self.transcription_path, "r", encoding="utf-8") as f:
                return f.read()
        return ""
    
    def save_transcription(self, transcription: str) -> str:
        """Salva transcri√ß√£o manualmente"""
        with open(self.transcription_path, "w", encoding="utf-8") as f:
            f.write(transcription)
        return self.transcription_path


# Fun√ß√£o de teste e demonstra√ß√£o
async def test_multimodal_service():
    """Testa o servi√ßo multimodal completo"""
    service = MultimodalAIService()
    
    # Simula uma transcri√ß√£o de teste
    test_transcription = """
    Paciente Jo√£o Silva, 45 anos, engenheiro civil. Comparece √† consulta relatando
    dor tor√°cica h√° 3 dias, tipo aperto, irradiando para bra√ßo esquerdo.
    Nega dispneia em repouso, mas refere cansa√ßo aos pequenos esfor√ßos.
    Hist√≥rico familiar de doen√ßa coronariana. Tabagista h√° 20 anos.
    Press√£o arterial: 150x95mmHg. Frequ√™ncia card√≠aca: 88bpm.
    Ausculta card√≠aca: bulhas r√≠tmicas, sem sopros.
    Solicita avalia√ß√£o cardiol√≥gica.
    """
    
    # Salva transcri√ß√£o para teste
    service.save_transcription(test_transcription)
    
    # Executa an√°lise completa
    results = await service.analyze_multimodal()
    
    print("=== RESULTADOS DO TESTE ===")
    print(f"Transcri√ß√£o: {len(results['transcription'])} caracteres")
    print(f"Dados do paciente: {results['patient_data']}")
    print(f"Relat√≥rio m√©dico: {len(results['medical_report'])} caracteres")
    print(f"Status: {results['status']}")
    
    return results


# Exemplo de uso
if __name__ == "__main__":
    # Configura vari√°vel de ambiente se necess√°rio
    if not os.getenv('OPENAI_API_KEY'):
        print("‚ö†Ô∏è Configure a vari√°vel OPENAI_API_KEY")
    else:
        # Executa teste
        asyncio.run(test_multimodal_service())